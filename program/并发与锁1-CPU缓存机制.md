# 并发与锁序列（一）--CPU缓存机制

​											-- 2020-01-15

操作系统必须要有一些机制和原语，以保证某些基本操作的原子性，比如处理器需要保证读一个字节或写一个字节是原子的，那么它是如何实现的呢?有两种机制：总线锁定和缓存一致性。

## 存储器种类

- 随机存储器：存储器在读写时， 所需要的时间和信息所在的位置无关
- 串行访问存储器： 读写时， 需要的时间和位置有关。包含： 顺序访问存储器（磁带）和直接访问存储器（磁盘）

## 随机存储器RAM

​	随机存储器（random access memory缩写RAM）也叫主存， 是与CPU直接交互数据的内部存储器。它可以随时随机读写（刷新时除外）。

​	现代的随机存取存储器依赖RAM存储数据。电容器充满电后代表1（二进制），未充电的代表0。由于电容器或多或少有漏电的情形，若不作特别处理，电荷会渐渐随时间流失而使数据发生错误。刷新是指重新为电容器充电，弥补流失了的电荷。DRAM的读取即有刷新的功效，但一般的定时刷新并不需要作完整的读取，只需作该芯片的一个列（Row）选择，整列的数据即可获得刷新，而同一时间内，所有相关记忆芯片均可同时作同一列选择，因此，在一段期间内逐一做完所有列的刷新，即可完成所有存储器的刷新。需要刷新正好解释了随机存取存储器的易失性。

​	正如其他精细的集成电路，随机存取存储器对环境的静电荷非常敏感。静电会干扰存储器内电容器的电荷，引致数据流失，甚至烧坏电路。故此触碰随机存取存储器前，应先用手触摸金属接地。

### DRAM与SRAM的区别

DRAM： 动态随机存储器， SRAM： 静态随机存储器。所谓的静态是指： 只要保持通电情况下， 存储的数据可以恒常保持。相对应的DRAM里面的数据需要周期性地更新才能保证数据不丢失。

与动态存储器（DRAM）相比，SRAM的带宽有很大改进—由于两条位线是反相，这种差分信号使得SRAM的抗噪声干扰能力很强。而DRAM的位线连接到存储电容，受困于电荷共享（charge sharing）使得其位线信号上下波动。另一项差别使得SRAM更快是其地址线各位元是同时工作选择出目标存储单元的字线，而DRAM往往为了降低成本，是先送出低半段的地址线的各比特，然后再送出高半段的地址线的各bit，这降低了DRAM封装的地址引脚的数量。

SRAM是比DRAM更为昂贵，但更为快速、非常低功耗（特别是在空闲状态）。因此SRAM首选用于带宽要求高，或者功耗要求低，或者二者兼而有之。SRAM比起DRAM更为容易控制，也更是随机访问。由于复杂的内部结构，SRAM比DRAM的占用面积更大，因而不适合用于更高储存密度低成本的应用，如PC内存。

DDR3与DDR4的区别

第四代双倍数据率同步动态随机存取存储器， 简称为DDR4 SDRAM），是一种高带宽的电脑存储器规格。它属于SDRAM家族的存储器产品，DDR4-SDRAM提供比DDR3/DDR2-SDRAM更低的供电电压以及更高的带宽。DDR3 SDRAM相比，DDR4 SDRAM拥有更高的时钟频率以及数据传输速率，

## 为什么需要CPU缓存

CPU，内存，磁盘速度不一致。为了提高运行效率, 提高cpu利用率（不需要等待资源），增加了缓存，加快cpu对数据的读写操作。我们为了提高 CPU 的利用率，添加了多级缓存，但是呢，数据的读取和保存都要在主存上进行，若是单线程是没有问题的，一条路走下去，该读读该写写。但是在多线程的情况下就会出现问题，因为每个线程都有自己的缓存，

CPU和内存DRAM性能对比

![](<F:/jkguo/notes/program/asserts/v2-1e2882cdeaafacac9ead8df35078d062_hd.jpg>)

CPU 内核独享寄存器、L1/L2，共享L3。 在早先时候只有单核CPU，那时只有L1和L2，后来有了多核CPU，为了效率和性能，就增加了共享的L3缓存。多颗CPU通过QPI连接。再后来，同一个主板上面也可以支持多颗CPU，多颗CPU也需要有通信和控制，才有了QPI。

![](<.\asserts\1545967845_18_w454_h310.png>)

![](<.\asserts\v2-f7df2460ef1d2af17bbf1b2a9d6bb550_hd.jpg>)



![](<.\asserts\v2-c8c982aa5384854a804ab3a5a57488f5_hd.jpg>)

CPU 中每个缓存行（caceh line）使用 4 种状态进行标记（使用额外的两位(bit)表示）。在 MESI 出现之前的解决缓存一致性的方案是总线锁机制，这种解决方案效率很低，锁住总线期间，其他 CPU 无法访问内存。



## L1 L2 L3缓存

​	现在的CPU中有好几个等级的缓存。通常L1和L2缓存都是每个CPU一个的, L1缓存有分为L1i和L1d，分别用来存储指令和数据。L2缓存是不区分指令和数据的。L3缓存多个核心共用一个，通常也不区分指令和数据。 还有一种缓存叫TLB，它主要用来缓存MMU使用的页表，通常我们讲缓存（cache)的时候是不算它的。

​	Cache存储数据是固定大小为单位的，称为一个Cache entry，这个单位称为Cache line或Cache block。给定Cache容量大小和Cache line size的情况下，它能存储的条目个数(number of cache entries)就是固定的。因为Cache是固定大小的，所以它从DRAM获取数据也是固定大小。对于X86来讲，它的Cache line大小与DDR3、4一次访存能得到的数据大小是一致的，即64Bytes。对于ARM来讲，较旧的架构(新的不知道有没有改）的Cache line是32Bytes，但一次内存访存只访问一半的数据也不太合适，所以它经常是一次填两个Cache line，叫做double fill。

​	Cache里存的数据是Memory中的**常用**数据一个拷贝，Cache比较小，不可以缓存Memory中的所有数据。当Cache存满后，再需要存入一个新的条目时，就需要把一个旧的条目从缓存中拿掉，这个过程称为evict，一个被evict的条目称为victim。缓存管理单元通过一定的算法决定哪些数据有资格留在Cache里，哪些数据需要从Cache里移出去。这个策略称为**替换策略（replacement policy)**。最简单的替换策略称为LRU(least recently used)，即Cache管理单元记录每个Cache line最近被访问的时间，每次需要evict时，选最近一次访问时间最久远的那一条做为victim。在实际使用中，LRU并不一定是最好的替换策略，在CPU设计的过程中，通常会不段对替换策略进行改进，每一款芯片几乎都使用了不同的替换策略。

​	CPU需要读写一个地址的时候，先去Cache中查找，如果数据不在Cache中，称为Cache miss，就需要从Memory中把这个地址所在的那个Cache line上的数据加载到Cache中。然后再把数返回给CPU。这时会伴随着另一个Cache 条目成为victim被替换出去。。如果发生了Cache Miss，就需要从Memory中取数据，这个取数据的过程中，CPU可以执行几十上百条指令的，如果等待数据时什么也不做时间就浪费了。可以在这个时候提高CPU使用效率的有两种方法，一个是乱序执行（out of order execution)，即把当前线程中后面的、不依赖于当前指令执行结果的指令拿过来提前执行，另一个是超线程技术，即把另一个线程的指令拿过来执行

### L1 L2 L3速度差别

- L1 cache: 3 cycles

- L2 cache: 11 cycles

- L3 cache: 25 cycles

- Main Memory: 100 cycles

​	L1/L2 Cache都是用SRAM做为存储介质，为什么说L1比L2快呢？这里面有三方面的原因：

- 存储容量不同导致的速度差异

  L1的容量通常比L2小，容量大的SRAM访问时间就越长，同样制程和设计的情况下，访问延时与容量的开方大致是成正比的。

- 离CPU远近导致的速度差异

  通常L1 Cache离CPU核心需要数据的地方更近，而L2 Cache则处于边缓位置，访问数据时，L2 Cache需要通过更远的铜线，甚至更多的电路，从而增加了延时。

  L1 Cache分为ICache（指令缓存）和DCache(数据缓存）,指令缓存ICache通常是放在CPU核心的指令预取单远附近的，数据缓存DCache通常是放在CPU核心的load/store单元附近。而L2 Cache是放在CPU pipeline之外的。

- 制程不同的造成的速度差异

  在实际设计制造时，针对L1/L2的不同角色，L1更加注重速度， L2更加注重节能和容量。在制程上这方面有体现，



​	L1/L2 Cache通常都是每个CPU核心一个。 L3 Cache通常都是各个核心共享的，而且DMA之类的设备也可以用。

## 缓存行

​	缓存行的存储空间是64字节。提高缓存效率需要注意更新数据对齐。更新频繁的数据独占一个缓存行， 只读的变量独占一个缓存行。

![](<.\asserts\1545967833_29_w614_h248.png>)

## 总线锁

​	前端总线(也叫CPU总线)是所有CPU与芯片组连接的主干道，负责CPU与外界所有部件的通信，包括高速缓存、内存、北桥，其控制总线向各个部件发送控制信号、通过地址总线发送地址信号指定其要访问的部件、通过数据总线双向传输。在CPU1要做 i++操作的时候，其在总线上发出一个LOCK#信号，其他处理器就不能操作缓存了该共享变量内存地址的缓存，也就是阻塞了其他CPU，使该处理器可以独享此共享内存。

​	但我们只需要对此共享变量的操作是原子就可以了，而总线锁定把CPU和内存的通信给锁住了，使得在锁定期间，其他处理器不能操作其他内存地址的数据，从而开销较大，所以后来的CPU都提供了缓存一致性机制，Intel的奔腾486之后就提供了这种优化。

## MESI协议

​	MESI协议是一种基于失效的缓存一致性的协议。是支持回写（write-back）缓存的最常用协议。与写通过（write through）缓存相比，回写缓冲能节约大量带宽。总是有“脏”（dirty）状态表示缓存中的数据与主存中不同。MESI协议要求在缓存不命中（miss）且数据块在另一个缓存时，允许缓存到缓存的数据复制。与MSI协议相比，MESI协议减少了主存的事务数量。这极大改善了性能

四纵缓存状态：

- 已修改（Modified）M:  缓存行是脏的(dirty)， 与主存的值不同。如果别的CPU内核要读驻存这块数据， 该存储行必须回写到主存， 状态变为共享（S）
- 独占（Exclude）E：缓存行只在当前缓存中， 但是干净的（clean）--缓存数据等同于主存数据。当别的缓存读取它时， 状态变为共享， 当前写数据时， 变为已修改状态
- 共享（Shared）S： 缓存行也存在与其他缓存中且是干净的。 缓存行可在任意时刻抛弃。
- 无效(Ivalid) I： 缓存行是无效的。

![](<.\asserts\Diagrama_MESI.GIF>)

处理器对缓存的请求:

1. PrRd: 处理器请求**读**一个缓存块
2. PrWr: 处理器请求**写**一个缓存块

总线对缓存的请求:

1. BusRd: 窥探器请求指出其他处理器请求**读**一个缓存块
2. BusRdX: 窥探器请求指出其他处理器请求**写**一个该处理器不拥有的缓存块
3. BusUpgr: 窥探器请求指出其他处理器请求**写**一个该处理器拥有的缓存块
4. Flush: 窥探器请求指出请求**回写**整个缓存到主存
5. FlushOpt: 窥探器请求指出整个缓存块被发到总线以发送给另外一个处理器（缓存到缓存的复制）

处理器操作带来的状态转化

- Invalid态-PrRd：
<pre>
给总线发BusRd信号
其他处理器看到BusRd，检查自己是否有有效的数据副本，通知发出请求的缓存
状态转换为(S)Shared, 如果其他缓存有有效的副本
状态转换为(E)Exclusive, 如果其他缓存都没有有效的副本
如果其他缓存有有效的副本, 其中一个缓存发出数据；否则从主存获得数据
</pre>
- Invalid态-PrWr：
<pre>
给总线发BusRdX信号
状态转换为(M)Modified
如果其他缓存有有效的副本, 其中一个缓存发出数据；否则从主存获得数据
如果其他缓存有有效的副本, 见到BusRdX信号后无效其副本
向缓存块中写入修改后的值
</pre>
- Exclusive-PrRd
<pre>
无总线事务生成
状态保持不变
读操作为缓存命中
</pre>

- Exclusive-PrWr
<pre>
无总线事务生成
状态转换为(M)Modified
向缓存块中写入修改后的值
</pre>
- Shared-PrRd
<pre>
无总线事务生成
状态保持不变
读操作为缓存命中
</pre>
- Shared-PrWr
<pre>
发出总线事务BusUpgr信号
状态转换为(M)Modified
其他缓存看到BusUpgr总线信号，标记其副本为(I)Invalid.
</pre>
- Modified-PrRd

<pre>
无总线事务生成
状态保持不变
读操作为缓存命中
</pre>
- Modified-PrWr

<pre>
无总线事务生成
状态保持不变
写操作为缓存命中
</pre>


不同总线操作带来的状态转化

- Invalid-BusRd: 状态保持不变，信号忽略
- Invalid-BusRdX/BusUpgr: 状态保持不变，信号忽略
- Exclusive-BusRd: 状态变为共享, 发出总线FlushOpt信号并发出块的内容
- Exclusive-BusRdX: 状态变为无效, 发出总线FlushOpt信号并发出块的内容
- Shared-BusRd: 状态变为共享可能发出总线FlushOpt信号并发出块的内容（设计时决定那个共享的缓存发出数据）
- Shared-BusRdX: 状态变为无效, 可能发出总线FlushOpt信号并发出块的内容（设计时决定那个共享的缓存发出数据）
- Modified-BusRd: 状态变为共享, 发出总线FlushOpt信号并发出块的内容，接收者为最初发出BusRd的缓存与主存控制器（回写主存）
- Modified-BusRdX: 状态变为无效, 发出总线FlushOpt信号并发出块的内容，接收者为最初发出BusRd的缓存与主存控制器（回写主存）

写操作仅在缓存行是已修改或独占状态时可自由执行。如果在共享状态，其他缓存都要先把该缓存行置为无效，这种广播操作称作Request For Ownership (RFO).缓存对已修改状态的缓存行，要监听各处理器对其的读请求并插入其数据到总线。缓存对共享状态的缓存行，要监听使其无效或请求拥有的广播，当匹配时把该缓存行置为无效。已修改状态、独占状态是精确的，匹配于该缓存行在系统中的实际情况。共享状态可以是不精确的: 如果别的缓存抛弃了该行，只有当前缓存拥有该行，但其状态没有变为独占。其他缓存不需要广播通知其抛弃操作。独占状态是一个优化机会：处理器修改共享状态的缓存行必须要先发出一个总线事务使得其他缓存中的该行失效；而独占状态下修改一行不需要总线事务。


## 参考文献

- <https://zhuanlan.zhihu.com/p/55429568>
- <https://zh.wikipedia.org/wiki/%E9%9D%99%E6%80%81%E9%9A%8F%E6%9C%BA%E5%AD%98%E5%8F%96%E5%AD%98%E5%82%A8%E5%99%A8>
- <https://zh.wikipedia.org/wiki/MESI%E5%8D%8F%E8%AE%AE>
- <https://zhuanlan.zhihu.com/p/31875174>